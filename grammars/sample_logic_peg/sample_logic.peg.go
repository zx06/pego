package sample_logic_peg

// Code generated by /tmp/go-build3017960765/b001/exe/peg -switch grammars/sample_logic_peg/sample_logic.peg DO NOT EDIT.

import (
	"fmt"
	"io"
	"os"
	"sort"
	"strconv"
	"strings"
)

const endSymbol rune = 1114112

/* The rule types inferred from the grammar are below. */
type pegRule uint8

const (
	ruleUnknown pegRule = iota
	ruleInput
	ruleExpr
	ruleTerm
	ruleFactor
	ruleFnExp
	ruleParameterDeclaration
	ruleParameter
	ruleIdentifier
	ruleIdNondigit
	ruleIdChar
	ruleKeyword
	ruleAND
	ruleOR
	ruleQUOTE
	rule_
	ruleWhiteSpace
	ruleLongComment
	ruleLineComment
	rulePragma
	ruleLPAR
	ruleRPAR
	ruleEOF
)

var rul3s = [...]string{
	"Unknown",
	"Input",
	"Expr",
	"Term",
	"Factor",
	"FnExp",
	"ParameterDeclaration",
	"Parameter",
	"Identifier",
	"IdNondigit",
	"IdChar",
	"Keyword",
	"AND",
	"OR",
	"QUOTE",
	"_",
	"WhiteSpace",
	"LongComment",
	"LineComment",
	"Pragma",
	"LPAR",
	"RPAR",
	"EOF",
}

type token32 struct {
	pegRule
	begin, end uint32
}

func (t *token32) String() string {
	return fmt.Sprintf("\x1B[34m%v\x1B[m %v %v", rul3s[t.pegRule], t.begin, t.end)
}

type node32 struct {
	token32
	up, next *node32
}

func (node *node32) print(w io.Writer, pretty bool, buffer string) {
	var print func(node *node32, depth int)
	print = func(node *node32, depth int) {
		for node != nil {
			for c := 0; c < depth; c++ {
				fmt.Fprintf(w, " ")
			}
			rule := rul3s[node.pegRule]
			quote := strconv.Quote(string(([]rune(buffer)[node.begin:node.end])))
			if !pretty {
				fmt.Fprintf(w, "%v %v\n", rule, quote)
			} else {
				fmt.Fprintf(w, "\x1B[36m%v\x1B[m %v\n", rule, quote)
			}
			if node.up != nil {
				print(node.up, depth+1)
			}
			node = node.next
		}
	}
	print(node, 0)
}

func (node *node32) Print(w io.Writer, buffer string) {
	node.print(w, false, buffer)
}

func (node *node32) PrettyPrint(w io.Writer, buffer string) {
	node.print(w, true, buffer)
}

type tokens32 struct {
	tree []token32
}

func (t *tokens32) Trim(length uint32) {
	t.tree = t.tree[:length]
}

func (t *tokens32) Print() {
	for _, token := range t.tree {
		fmt.Println(token.String())
	}
}

func (t *tokens32) AST() *node32 {
	type element struct {
		node *node32
		down *element
	}
	tokens := t.Tokens()
	var stack *element
	for _, token := range tokens {
		if token.begin == token.end {
			continue
		}
		node := &node32{token32: token}
		for stack != nil && stack.node.begin >= token.begin && stack.node.end <= token.end {
			stack.node.next = node.up
			node.up = stack.node
			stack = stack.down
		}
		stack = &element{node: node, down: stack}
	}
	if stack != nil {
		return stack.node
	}
	return nil
}

func (t *tokens32) PrintSyntaxTree(buffer string) {
	t.AST().Print(os.Stdout, buffer)
}

func (t *tokens32) WriteSyntaxTree(w io.Writer, buffer string) {
	t.AST().Print(w, buffer)
}

func (t *tokens32) PrettyPrintSyntaxTree(buffer string) {
	t.AST().PrettyPrint(os.Stdout, buffer)
}

func (t *tokens32) Add(rule pegRule, begin, end, index uint32) {
	tree, i := t.tree, int(index)
	if i >= len(tree) {
		t.tree = append(tree, token32{pegRule: rule, begin: begin, end: end})
		return
	}
	tree[i] = token32{pegRule: rule, begin: begin, end: end}
}

func (t *tokens32) Tokens() []token32 {
	return t.tree
}

type SampleLogic struct {
	Buffer string
	buffer []rune
	rules  [23]func() bool
	parse  func(rule ...int) error
	reset  func()
	Pretty bool
	tokens32
}

func (p *SampleLogic) Parse(rule ...int) error {
	return p.parse(rule...)
}

func (p *SampleLogic) Reset() {
	p.reset()
}

type textPosition struct {
	line, symbol int
}

type textPositionMap map[int]textPosition

func translatePositions(buffer []rune, positions []int) textPositionMap {
	length, translations, j, line, symbol := len(positions), make(textPositionMap, len(positions)), 0, 1, 0
	sort.Ints(positions)

search:
	for i, c := range buffer {
		if c == '\n' {
			line, symbol = line+1, 0
		} else {
			symbol++
		}
		if i == positions[j] {
			translations[positions[j]] = textPosition{line, symbol}
			for j++; j < length; j++ {
				if i != positions[j] {
					continue search
				}
			}
			break search
		}
	}

	return translations
}

type parseError struct {
	p   *SampleLogic
	max token32
}

func (e *parseError) Error() string {
	tokens, err := []token32{e.max}, "\n"
	positions, p := make([]int, 2*len(tokens)), 0
	for _, token := range tokens {
		positions[p], p = int(token.begin), p+1
		positions[p], p = int(token.end), p+1
	}
	translations := translatePositions(e.p.buffer, positions)
	format := "parse error near %v (line %v symbol %v - line %v symbol %v):\n%v\n"
	if e.p.Pretty {
		format = "parse error near \x1B[34m%v\x1B[m (line %v symbol %v - line %v symbol %v):\n%v\n"
	}
	for _, token := range tokens {
		begin, end := int(token.begin), int(token.end)
		err += fmt.Sprintf(format,
			rul3s[token.pegRule],
			translations[begin].line, translations[begin].symbol,
			translations[end].line, translations[end].symbol,
			strconv.Quote(string(e.p.buffer[begin:end])))
	}

	return err
}

func (p *SampleLogic) PrintSyntaxTree() {
	if p.Pretty {
		p.tokens32.PrettyPrintSyntaxTree(p.Buffer)
	} else {
		p.tokens32.PrintSyntaxTree(p.Buffer)
	}
}

func (p *SampleLogic) WriteSyntaxTree(w io.Writer) {
	p.tokens32.WriteSyntaxTree(w, p.Buffer)
}

func (p *SampleLogic) SprintSyntaxTree() string {
	var bldr strings.Builder
	p.WriteSyntaxTree(&bldr)
	return bldr.String()
}

func Pretty(pretty bool) func(*SampleLogic) error {
	return func(p *SampleLogic) error {
		p.Pretty = pretty
		return nil
	}
}

func Size(size int) func(*SampleLogic) error {
	return func(p *SampleLogic) error {
		p.tokens32 = tokens32{tree: make([]token32, 0, size)}
		return nil
	}
}
func (p *SampleLogic) Init(options ...func(*SampleLogic) error) error {
	var (
		max                  token32
		position, tokenIndex uint32
		buffer               []rune
	)
	for _, option := range options {
		err := option(p)
		if err != nil {
			return err
		}
	}
	p.reset = func() {
		max = token32{}
		position, tokenIndex = 0, 0

		p.buffer = []rune(p.Buffer)
		if len(p.buffer) == 0 || p.buffer[len(p.buffer)-1] != endSymbol {
			p.buffer = append(p.buffer, endSymbol)
		}
		buffer = p.buffer
	}
	p.reset()

	_rules := p.rules
	tree := p.tokens32
	p.parse = func(rule ...int) error {
		r := 1
		if len(rule) > 0 {
			r = rule[0]
		}
		matches := p.rules[r]()
		p.tokens32 = tree
		if matches {
			p.Trim(tokenIndex)
			return nil
		}
		return &parseError{p, max}
	}

	add := func(rule pegRule, begin uint32) {
		tree.Add(rule, begin, position, tokenIndex)
		tokenIndex++
		if begin != position && position > max.end {
			max = token32{rule, begin, position}
		}
	}

	matchDot := func() bool {
		if buffer[position] != endSymbol {
			position++
			return true
		}
		return false
	}

	/*matchChar := func(c byte) bool {
		if buffer[position] == c {
			position++
			return true
		}
		return false
	}*/

	/*matchRange := func(lower byte, upper byte) bool {
		if c := buffer[position]; c >= lower && c <= upper {
			position++
			return true
		}
		return false
	}*/

	_rules = [...]func() bool{
		nil,
		/* 0 Input <- <(_ Expr _ EOF)> */
		func() bool {
			position0, tokenIndex0 := position, tokenIndex
			{
				position1 := position
				if !_rules[rule_]() {
					goto l0
				}
				if !_rules[ruleExpr]() {
					goto l0
				}
				if !_rules[rule_]() {
					goto l0
				}
				if !_rules[ruleEOF]() {
					goto l0
				}
				add(ruleInput, position1)
			}
			return true
		l0:
			position, tokenIndex = position0, tokenIndex0
			return false
		},
		/* 1 Expr <- <(_ Term (_ AND _ Term)* _)> */
		func() bool {
			position2, tokenIndex2 := position, tokenIndex
			{
				position3 := position
				if !_rules[rule_]() {
					goto l2
				}
				if !_rules[ruleTerm]() {
					goto l2
				}
			l4:
				{
					position5, tokenIndex5 := position, tokenIndex
					if !_rules[rule_]() {
						goto l5
					}
					if !_rules[ruleAND]() {
						goto l5
					}
					if !_rules[rule_]() {
						goto l5
					}
					if !_rules[ruleTerm]() {
						goto l5
					}
					goto l4
				l5:
					position, tokenIndex = position5, tokenIndex5
				}
				if !_rules[rule_]() {
					goto l2
				}
				add(ruleExpr, position3)
			}
			return true
		l2:
			position, tokenIndex = position2, tokenIndex2
			return false
		},
		/* 2 Term <- <(_ Factor (_ OR _ Factor)* _)> */
		func() bool {
			position6, tokenIndex6 := position, tokenIndex
			{
				position7 := position
				if !_rules[rule_]() {
					goto l6
				}
				if !_rules[ruleFactor]() {
					goto l6
				}
			l8:
				{
					position9, tokenIndex9 := position, tokenIndex
					if !_rules[rule_]() {
						goto l9
					}
					if !_rules[ruleOR]() {
						goto l9
					}
					if !_rules[rule_]() {
						goto l9
					}
					if !_rules[ruleFactor]() {
						goto l9
					}
					goto l8
				l9:
					position, tokenIndex = position9, tokenIndex9
				}
				if !_rules[rule_]() {
					goto l6
				}
				add(ruleTerm, position7)
			}
			return true
		l6:
			position, tokenIndex = position6, tokenIndex6
			return false
		},
		/* 3 Factor <- <((_ LPAR Expr RPAR _) / FnExp)> */
		func() bool {
			position10, tokenIndex10 := position, tokenIndex
			{
				position11 := position
				{
					position12, tokenIndex12 := position, tokenIndex
					if !_rules[rule_]() {
						goto l13
					}
					if !_rules[ruleLPAR]() {
						goto l13
					}
					if !_rules[ruleExpr]() {
						goto l13
					}
					if !_rules[ruleRPAR]() {
						goto l13
					}
					if !_rules[rule_]() {
						goto l13
					}
					goto l12
				l13:
					position, tokenIndex = position12, tokenIndex12
					if !_rules[ruleFnExp]() {
						goto l10
					}
				}
			l12:
				add(ruleFactor, position11)
			}
			return true
		l10:
			position, tokenIndex = position10, tokenIndex10
			return false
		},
		/* 4 FnExp <- <(Identifier LPAR ParameterDeclaration RPAR)> */
		func() bool {
			position14, tokenIndex14 := position, tokenIndex
			{
				position15 := position
				if !_rules[ruleIdentifier]() {
					goto l14
				}
				if !_rules[ruleLPAR]() {
					goto l14
				}
				if !_rules[ruleParameterDeclaration]() {
					goto l14
				}
				if !_rules[ruleRPAR]() {
					goto l14
				}
				add(ruleFnExp, position15)
			}
			return true
		l14:
			position, tokenIndex = position14, tokenIndex14
			return false
		},
		/* 5 ParameterDeclaration <- <(QUOTE Parameter* QUOTE)> */
		func() bool {
			position16, tokenIndex16 := position, tokenIndex
			{
				position17 := position
				if !_rules[ruleQUOTE]() {
					goto l16
				}
			l18:
				{
					position19, tokenIndex19 := position, tokenIndex
					if !_rules[ruleParameter]() {
						goto l19
					}
					goto l18
				l19:
					position, tokenIndex = position19, tokenIndex19
				}
				if !_rules[ruleQUOTE]() {
					goto l16
				}
				add(ruleParameterDeclaration, position17)
			}
			return true
		l16:
			position, tokenIndex = position16, tokenIndex16
			return false
		},
		/* 6 Parameter <- <(!('\'' / '\'') .)> */
		func() bool {
			position20, tokenIndex20 := position, tokenIndex
			{
				position21 := position
				{
					position22, tokenIndex22 := position, tokenIndex
					{
						position23, tokenIndex23 := position, tokenIndex
						if buffer[position] != rune('\'') {
							goto l24
						}
						position++
						goto l23
					l24:
						position, tokenIndex = position23, tokenIndex23
						if buffer[position] != rune('\'') {
							goto l22
						}
						position++
					}
				l23:
					goto l20
				l22:
					position, tokenIndex = position22, tokenIndex22
				}
				if !matchDot() {
					goto l20
				}
				add(ruleParameter, position21)
			}
			return true
		l20:
			position, tokenIndex = position20, tokenIndex20
			return false
		},
		/* 7 Identifier <- <(!Keyword IdNondigit IdChar*)> */
		func() bool {
			position25, tokenIndex25 := position, tokenIndex
			{
				position26 := position
				{
					position27, tokenIndex27 := position, tokenIndex
					if !_rules[ruleKeyword]() {
						goto l27
					}
					goto l25
				l27:
					position, tokenIndex = position27, tokenIndex27
				}
				if !_rules[ruleIdNondigit]() {
					goto l25
				}
			l28:
				{
					position29, tokenIndex29 := position, tokenIndex
					if !_rules[ruleIdChar]() {
						goto l29
					}
					goto l28
				l29:
					position, tokenIndex = position29, tokenIndex29
				}
				add(ruleIdentifier, position26)
			}
			return true
		l25:
			position, tokenIndex = position25, tokenIndex25
			return false
		},
		/* 8 IdNondigit <- <((&('_') '_') | (&('A' | 'B' | 'C' | 'D' | 'E' | 'F' | 'G' | 'H' | 'I' | 'J' | 'K' | 'L' | 'M' | 'N' | 'O' | 'P' | 'Q' | 'R' | 'S' | 'T' | 'U' | 'V' | 'W' | 'X' | 'Y' | 'Z') [A-Z]) | (&('a' | 'b' | 'c' | 'd' | 'e' | 'f' | 'g' | 'h' | 'i' | 'j' | 'k' | 'l' | 'm' | 'n' | 'o' | 'p' | 'q' | 'r' | 's' | 't' | 'u' | 'v' | 'w' | 'x' | 'y' | 'z') [a-z]))> */
		func() bool {
			position30, tokenIndex30 := position, tokenIndex
			{
				position31 := position
				{
					switch buffer[position] {
					case '_':
						if buffer[position] != rune('_') {
							goto l30
						}
						position++
					case 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z':
						if c := buffer[position]; c < rune('A') || c > rune('Z') {
							goto l30
						}
						position++
					default:
						if c := buffer[position]; c < rune('a') || c > rune('z') {
							goto l30
						}
						position++
					}
				}

				add(ruleIdNondigit, position31)
			}
			return true
		l30:
			position, tokenIndex = position30, tokenIndex30
			return false
		},
		/* 9 IdChar <- <((&('_') '_') | (&('0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9') [0-9]) | (&('A' | 'B' | 'C' | 'D' | 'E' | 'F' | 'G' | 'H' | 'I' | 'J' | 'K' | 'L' | 'M' | 'N' | 'O' | 'P' | 'Q' | 'R' | 'S' | 'T' | 'U' | 'V' | 'W' | 'X' | 'Y' | 'Z') [A-Z]) | (&('a' | 'b' | 'c' | 'd' | 'e' | 'f' | 'g' | 'h' | 'i' | 'j' | 'k' | 'l' | 'm' | 'n' | 'o' | 'p' | 'q' | 'r' | 's' | 't' | 'u' | 'v' | 'w' | 'x' | 'y' | 'z') [a-z]))> */
		func() bool {
			position33, tokenIndex33 := position, tokenIndex
			{
				position34 := position
				{
					switch buffer[position] {
					case '_':
						if buffer[position] != rune('_') {
							goto l33
						}
						position++
					case '0', '1', '2', '3', '4', '5', '6', '7', '8', '9':
						if c := buffer[position]; c < rune('0') || c > rune('9') {
							goto l33
						}
						position++
					case 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z':
						if c := buffer[position]; c < rune('A') || c > rune('Z') {
							goto l33
						}
						position++
					default:
						if c := buffer[position]; c < rune('a') || c > rune('z') {
							goto l33
						}
						position++
					}
				}

				add(ruleIdChar, position34)
			}
			return true
		l33:
			position, tokenIndex = position33, tokenIndex33
			return false
		},
		/* 10 Keyword <- <(AND / OR)> */
		func() bool {
			position36, tokenIndex36 := position, tokenIndex
			{
				position37 := position
				{
					position38, tokenIndex38 := position, tokenIndex
					if !_rules[ruleAND]() {
						goto l39
					}
					goto l38
				l39:
					position, tokenIndex = position38, tokenIndex38
					if !_rules[ruleOR]() {
						goto l36
					}
				}
			l38:
				add(ruleKeyword, position37)
			}
			return true
		l36:
			position, tokenIndex = position36, tokenIndex36
			return false
		},
		/* 11 AND <- <('a' 'n' 'd')> */
		func() bool {
			position40, tokenIndex40 := position, tokenIndex
			{
				position41 := position
				if buffer[position] != rune('a') {
					goto l40
				}
				position++
				if buffer[position] != rune('n') {
					goto l40
				}
				position++
				if buffer[position] != rune('d') {
					goto l40
				}
				position++
				add(ruleAND, position41)
			}
			return true
		l40:
			position, tokenIndex = position40, tokenIndex40
			return false
		},
		/* 12 OR <- <('o' 'r')> */
		func() bool {
			position42, tokenIndex42 := position, tokenIndex
			{
				position43 := position
				if buffer[position] != rune('o') {
					goto l42
				}
				position++
				if buffer[position] != rune('r') {
					goto l42
				}
				position++
				add(ruleOR, position43)
			}
			return true
		l42:
			position, tokenIndex = position42, tokenIndex42
			return false
		},
		/* 13 QUOTE <- <('"' / '\'')> */
		func() bool {
			position44, tokenIndex44 := position, tokenIndex
			{
				position45 := position
				{
					position46, tokenIndex46 := position, tokenIndex
					if buffer[position] != rune('"') {
						goto l47
					}
					position++
					goto l46
				l47:
					position, tokenIndex = position46, tokenIndex46
					if buffer[position] != rune('\'') {
						goto l44
					}
					position++
				}
			l46:
				add(ruleQUOTE, position45)
			}
			return true
		l44:
			position, tokenIndex = position44, tokenIndex44
			return false
		},
		/* 14 _ <- <(LongComment / ((&('#') Pragma) | (&('/') LineComment) | (&('\t' | '\n' | '\r' | ' ') WhiteSpace)))*> */
		func() bool {
			{
				position49 := position
			l50:
				{
					position51, tokenIndex51 := position, tokenIndex
					{
						position52, tokenIndex52 := position, tokenIndex
						if !_rules[ruleLongComment]() {
							goto l53
						}
						goto l52
					l53:
						position, tokenIndex = position52, tokenIndex52
						{
							switch buffer[position] {
							case '#':
								if !_rules[rulePragma]() {
									goto l51
								}
							case '/':
								if !_rules[ruleLineComment]() {
									goto l51
								}
							default:
								if !_rules[ruleWhiteSpace]() {
									goto l51
								}
							}
						}

					}
				l52:
					goto l50
				l51:
					position, tokenIndex = position51, tokenIndex51
				}
				add(rule_, position49)
			}
			return true
		},
		/* 15 WhiteSpace <- <((&('\t') '\t') | (&('\r') '\r') | (&('\n') '\n') | (&(' ') ' '))> */
		func() bool {
			position55, tokenIndex55 := position, tokenIndex
			{
				position56 := position
				{
					switch buffer[position] {
					case '\t':
						if buffer[position] != rune('\t') {
							goto l55
						}
						position++
					case '\r':
						if buffer[position] != rune('\r') {
							goto l55
						}
						position++
					case '\n':
						if buffer[position] != rune('\n') {
							goto l55
						}
						position++
					default:
						if buffer[position] != rune(' ') {
							goto l55
						}
						position++
					}
				}

				add(ruleWhiteSpace, position56)
			}
			return true
		l55:
			position, tokenIndex = position55, tokenIndex55
			return false
		},
		/* 16 LongComment <- <('/' '*' (!('*' '/') .)* ('*' '/'))> */
		func() bool {
			position58, tokenIndex58 := position, tokenIndex
			{
				position59 := position
				if buffer[position] != rune('/') {
					goto l58
				}
				position++
				if buffer[position] != rune('*') {
					goto l58
				}
				position++
			l60:
				{
					position61, tokenIndex61 := position, tokenIndex
					{
						position62, tokenIndex62 := position, tokenIndex
						if buffer[position] != rune('*') {
							goto l62
						}
						position++
						if buffer[position] != rune('/') {
							goto l62
						}
						position++
						goto l61
					l62:
						position, tokenIndex = position62, tokenIndex62
					}
					if !matchDot() {
						goto l61
					}
					goto l60
				l61:
					position, tokenIndex = position61, tokenIndex61
				}
				if buffer[position] != rune('*') {
					goto l58
				}
				position++
				if buffer[position] != rune('/') {
					goto l58
				}
				position++
				add(ruleLongComment, position59)
			}
			return true
		l58:
			position, tokenIndex = position58, tokenIndex58
			return false
		},
		/* 17 LineComment <- <('/' '/' (!'\n' .)*)> */
		func() bool {
			position63, tokenIndex63 := position, tokenIndex
			{
				position64 := position
				if buffer[position] != rune('/') {
					goto l63
				}
				position++
				if buffer[position] != rune('/') {
					goto l63
				}
				position++
			l65:
				{
					position66, tokenIndex66 := position, tokenIndex
					{
						position67, tokenIndex67 := position, tokenIndex
						if buffer[position] != rune('\n') {
							goto l67
						}
						position++
						goto l66
					l67:
						position, tokenIndex = position67, tokenIndex67
					}
					if !matchDot() {
						goto l66
					}
					goto l65
				l66:
					position, tokenIndex = position66, tokenIndex66
				}
				add(ruleLineComment, position64)
			}
			return true
		l63:
			position, tokenIndex = position63, tokenIndex63
			return false
		},
		/* 18 Pragma <- <('#' (!'\n' .)*)> */
		func() bool {
			position68, tokenIndex68 := position, tokenIndex
			{
				position69 := position
				if buffer[position] != rune('#') {
					goto l68
				}
				position++
			l70:
				{
					position71, tokenIndex71 := position, tokenIndex
					{
						position72, tokenIndex72 := position, tokenIndex
						if buffer[position] != rune('\n') {
							goto l72
						}
						position++
						goto l71
					l72:
						position, tokenIndex = position72, tokenIndex72
					}
					if !matchDot() {
						goto l71
					}
					goto l70
				l71:
					position, tokenIndex = position71, tokenIndex71
				}
				add(rulePragma, position69)
			}
			return true
		l68:
			position, tokenIndex = position68, tokenIndex68
			return false
		},
		/* 19 LPAR <- <'('> */
		func() bool {
			position73, tokenIndex73 := position, tokenIndex
			{
				position74 := position
				if buffer[position] != rune('(') {
					goto l73
				}
				position++
				add(ruleLPAR, position74)
			}
			return true
		l73:
			position, tokenIndex = position73, tokenIndex73
			return false
		},
		/* 20 RPAR <- <')'> */
		func() bool {
			position75, tokenIndex75 := position, tokenIndex
			{
				position76 := position
				if buffer[position] != rune(')') {
					goto l75
				}
				position++
				add(ruleRPAR, position76)
			}
			return true
		l75:
			position, tokenIndex = position75, tokenIndex75
			return false
		},
		/* 21 EOF <- <!.> */
		func() bool {
			position77, tokenIndex77 := position, tokenIndex
			{
				position78 := position
				{
					position79, tokenIndex79 := position, tokenIndex
					if !matchDot() {
						goto l79
					}
					goto l77
				l79:
					position, tokenIndex = position79, tokenIndex79
				}
				add(ruleEOF, position78)
			}
			return true
		l77:
			position, tokenIndex = position77, tokenIndex77
			return false
		},
	}
	p.rules = _rules
	return nil
}
